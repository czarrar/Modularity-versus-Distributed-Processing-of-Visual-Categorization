
# Methods

In this study, our goal was to test for brain localization or distributed processing in representations of various visual categories. We used three analytic approaches. First was the univariate brain activity. This is simple, has been done before, and ….. Second is examining patterns of brain activity within each anatomical brain area and comparing the category information relative to other categories. Third, is the classification task where we can compare both activity within region between categories and this information across regions to see if there are any redundancies.

## Participants

Twenty right-handed, healthy adults (X females, age range Y-Z years, mean X years) participated in the study. All had normal or corrected-to-normal vision and no history of neurological or psychiatric illnesses. The protocol was approved by the Duke Human Investigation Committee, and informed consent was obtained for all participants. 

## Stimuli

336 stimuli were generated: circles, faces, fruits, letters, objects, and vehicles...

## Procedure

Participants viewed a series of color images that were randomly selected from one of five categories: Faces, Fruits, Letter Strings, Objects, and Vehicles (Fig. X). Interspersed between these stimuli were scrambled images, which were constructed by performing a two-dimensional (2D) Fourier transform of stimuli from one of the five categories, permuting the phase spectrum, and then performing an inverse transform. These “phase-scrambled” images thus had the same spatial frequencies and overall luminance as the non-scrambled stimuli but category membership was unrecognizable. Consequently, the scrambled images served as a baseline, controlling for any low-level brain response to visual stimuli. Participants were instructed to press the spacebar as quickly as possible when a target (circle) appeared. The target stimulus appeared on ∼12% of all trials or 36 times. Each image was displayed for 500 ms with a jittered interstimulus interval (ISI) that varied randomly between X and Y ms. Participants viewed a total of 60 exemplar images from each category. Images from each category were shown 5-7 times in each run with 10 runs in total.

## Image Acquisition and Preprocessing

[template...replace with own stuff] Data were acquired using a 3T Siemens TIM Trio scanner with a 32-channel head coil. Functional images were acquired using a multiband echo-planar pulse sequence (TR = 1000 ms, TE = 32 ms, flip angle = 62°, acceleration factor = 3, FOV = 210 × 210 mm, matrix = 84 × 84, slice thickness = 2.5 mm, 52 slices, voxel size = 2.5 mm3). A high-resolution structural image was acquired for registration using a 3D MP-RAGE sequence (TR = 2530 ms, TE = 2.77 ms, flip angle = 7°, FOV = 256 × 256 mm, matrix = 256 × 256, slice thickness = 1 mm, 176 slices).

Image preprocessing was performed using custom scripts (http://github.com/HumanNeuroscienceLab/repsim), which build on AFNI (v 2014-10-23 OpenMP, http://afni.nimh.nih.gov/afni) and FSL (v5.0.7, http://www.fmrib.ox.ac.uk/fsl). Structural images were skull-stripped with AFNI's 3dSkullStrip (cite). For the functional data, the first 6 volumes (6 s) were discarded to allow for MR equilibration. Functional images then underwent motion correction using AFNI’s 3dvolreg, skull stripping of the mean functional image using FSL’s BET (Smith 2002), spatial smoothing with a 4-mm FWHM Gaussian mask using FSL’s SUSAN (Smith and Brady 1997), high-pass filtering with a 0.01 Hz cut-off to remove low-frequency drift using FSL, and mean-based global intensity normalization. Finally, the functional images were registered to the high-resolution structural images with boundary-based registration using FSL’s Flirt. The structural images were in turn nonlinearly registered to the Montreal Neurological Institute’s MNI152 template (2 mm isotropic) using FSL’s FNIRT (Andersson et al. 2007) and this transform was then applied to the functional images in anatomical space.

## fMRI Data Analysis

### Univariate Brain Activity

[goal here is to see levels of overlap or not with a simple univariate brain analysis]

Whole-brain voxel-wise regression analyses were performed at the subject-level using AFNI’s 3dDeconvolve and 3dREMLfit functions, which provide temporal pre-whitening via an autoregressive model. The linear model consisted of six explanatory variables for trials associated with faces, fruits, letter strings, objects, vehicles, or circles (the target). All variables were modeled as boxcar functions, where a value of 1 was assigned to time-points when a non-scrambled stimulus was on the screen (0.5-s per trial) and a value of 0 to time-points when the face was not on the screen, and then convolved with a double-gamma function (AFNI’s SPMG1). Regressors of no interest included baseline effects of each run and 6 head movement parameters. Contrasts were defined to identity brain regions that showed increased activity when viewing each stimuli versus the average activity for all other stimuli. Following individual analyses, whole-brain group analysis was performed using AFNI’s 3dMEMA (Chen et al. 2012), a program that incorporates individual beta precision estimates into group effects using a mixed-effects meta-analytic approach. Clusters were defined as contiguous sets of voxels with Z > 1.96 and then thresholded using Gaussian random field theory (cluster probability p < 0.05) to correct for multiple comparisons (Worsley et al. 1996). Finally, we computed the overlap in significant brain activity for each category versus the average to assess localized versus shared activity across categories. We conducted these analyses for activity across all the runs as well as the even runs and odd runs. 

### Correlation of Brain Activity Patterns

[mention that looking to measure shared information for each category and between categories]

We measured category information based on patterns of brain activity in anatomical regions-of-interest (ROIs) taken from the Harvard-Oxford anatomical atlas (25% probability).  For each subject, we measured partial correlations using regression between pairs of activity patterns from the even versus odd runs. For example, to measure category information for faces, we correlated activity patterns for faces between even and odd runs while controlling for activity found in the other four categories (Fig 2). This correlation was computed in two steps. First, we regressed face activity patterns from the even runs onto odd runs while controlling for activity patterns found in the other four categories from the even runs (face-even ~ face-odd).  Then, we flipped the runs and regressed face activity patterns from odd runs onto even runs while controlling for every other category activity patterns from the odd runs (face-odd ~ face-even). The resulting two correlation values were combined as the sqrt(R2) (cite Whittaker 1990). Significance estimates were taken as the average of the two correlation pairs and were thresholded at *p* < 0.05. We computed partial correlations in the same way between other even-odd run pairs from the same category or from different categories while controlling for any patterns of activity found in other categories. Consequently, the partial correlation reflected the amount of unique information shared by a pair of categories that could not be explained by activity in any other category (Fig 3). Furthermore by comparing activity between independent sets of runs, we were able to measure the stimulus-driven information in category-specific brain activity and control for any intrinsic fluctuations in brain signal found in specific runs (cite). To obtain group average estimates, we repeated our analysis after concatenating each subject’s pattern of brain activity for each category and region. This approach to the group average is similar to taking the average of each individual subject’s correlation matrix (cite?) but simplifies our approach to significance testing.

Partial correlations were computed using linear ridge regression. Ridge regression accounts for collinearities among regressors and prevents overfitting by penalizing model parameters (cite). We use the implementation found in the R package *ridge*, which provides significance testing (Cule et al., 2011) and automatic selection of the penalization parameter (Cule et al., 2012). We apply ridge regression to partial correlations by adapting functions from the R package *parcor* (cite). In supplementary materials, we also compared the ridge regression with linear regression or the lasso. We found that the ridge-based approach produced the most consistent partial correlation matrices across subjects and had the most robust effects, motivating the selection of the ridge regression for our correlation analyses here.

[todo]. We repeated the adaptive lasso correlations on functional parcellations, which more accurately reflect the boundary between distinct brain regions when compared to anatomical ROIs (cite). We constrained our parcellation analyses to visual areas in the Harvard-Oxford Atlas, which were identified based on anatomical, electrophysiological, behavioral, lesion, and functional imaging studies in nonhuman primates and in humans as described by Mesulam (2000). Table 1 lists the regions in the Harvard-Oxford atlas that were labelled as visual areas. The parcels were generated within the visual areas using a previously validated region growing approach (Blumensath et al., 2013). For each subject, we first concatenated their functional time-series across 10 runs. Then in volume space, we find representative seed time-courses of an area and grow those seed voxels into functionally homogenous regions. Figure 4 shows sample output of the functional parcellations within visual regions for one subject.

### Classification of Brain Activity Patterns

In our previous adaptive lasso analyses, patterns of activity unique to a category were not localized to specific voxels and the same activity patterns could repeat across brain areas hence reflecting redundant information. Here, we account for any redundant category information found across brain areas by using the multinomial sparse group lasso (cite). In one model, we identify the minimal number of regions (i.e., those anatomical regions with unique category information) that best predict the category of brain activation patterns. Our classification analyses were done for each subject and use activation patterns from individual trials (300 trials consisting of 5 categories of 60 trials).

*Data Reduction.* For computational efficiency, we first reduce the dimensionality of each anatomical region’s voxelwise data to a subset of the top principal components. We determined those top components by comparing the eigenvalue of each component to a null distribution of eigenvalues generated from random uncorrelated data (cite). A total of 100 random sets of eigenvalues were generated. Principal components were kept if their eigenvalues were larger than 95% of the random eigenvalues (i.e., _p_ < 0.05). After obtaining the top components for each ROI, we combined those components together creating a matrix of T (trials) x P (components) where T = 300 trials and P = the total number of components across all ROIs.

*Multinomial Sparse Group-Lasso.* We used the implementation of the multinomial sparse group lasso found in the R package msgl (cite). Our classification approach uses patterns of brain activity to predict the category of visual stimuli in each trial for each subject. The goal is to identify the subset of anatomical regions that contain unique information in best predicting category membership. Each anatomical region is multivariate and contains the top principal components of the voxelwise brain activity in that region. Separate parameters of the data are estimated for each category in a multinomial logistic regression model, which generalizes the logistic regression to multi-class problems (cite). The model is fit using a sparse group lasso that removes redundant or unimportant groups (i.e., anatomical regions) and within important groups removes unimportant features (i.e., principal components of voxelwise data) (cite). Thus, in the sparse group lasso, the relevant principal components in an anatomical region are retained or discarded together. The best parameters and group/feature subset are selected by using a leave-one run out cross-validation. On each fold, data from 270 trials of each region’s top components are used to train the model and data from the remaining 30 trials are used for testing. The average classification accuracy for each trial and the average percent of anatomical regions retained by the model is calculated across all folds. In addition, we calculated the average accuracy and percent of regions retained by the model for each category. We empirically estimated the null distribution for the classification accuracy and regions retained by using a permutation test. The category labels for each trial were randomly shuffled and the model fit was re-calculated 200 times. Our observed values were then compared to the permuted distribution to compute p-values.

*Multinomial Elastic-Net*. To assess the value of combining all regions together as in the previous model, we applied classification analyses that predict category membership separately for each anatomical region. We used the elastic-net model found in the *glmnet* R package (cite) and tuned the model for two possible parameters: alpha and lambda. The alpha parameter reflects the type of penalty, and we used the lasso (alpha=1), mix of lasso-ridge (alpha=0.5), and the ridge (alpha=0). The lasso selects more relevant features and discards the other features, whereas ridge regression never fully discards any features and just reduces all the beta estimates. The lambda parameter refers to the degree of penalization in the model and a range of values were automatically selected by the *glmnet* function. The best parameter values were determined by leave one run out cross-validation. Permutation tests were used to calculate the null distribution and compute p-values for classification accuracy and the number of features retained.

*Visual Area Parcellations*. We repeated our Harvard-Oxford based classification analysis on functional parcellations in visual areas.